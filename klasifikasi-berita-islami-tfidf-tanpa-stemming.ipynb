{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport json\n\nimport spacy\nfrom spacy import displacy\nfrom collections import Counter\nimport en_core_web_lg\n\nnlp = en_core_web_lg.load()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:55.390725Z","iopub.execute_input":"2022-06-16T16:11:55.391178Z","iopub.status.idle":"2022-06-16T16:11:58.538482Z","shell.execute_reply.started":"2022-06-16T16:11:55.391142Z","shell.execute_reply":"2022-06-16T16:11:58.537494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\n\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom imblearn.under_sampling import InstanceHardnessThreshold\nfrom sklearn.svm import LinearSVC\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, GaussianNB\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.540182Z","iopub.execute_input":"2022-06-16T16:11:58.540541Z","iopub.status.idle":"2022-06-16T16:11:58.549899Z","shell.execute_reply.started":"2022-06-16T16:11:58.54051Z","shell.execute_reply":"2022-06-16T16:11:58.548858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib\nimport matplotlib.pyplot as plt\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.552248Z","iopub.execute_input":"2022-06-16T16:11:58.552744Z","iopub.status.idle":"2022-06-16T16:11:58.570704Z","shell.execute_reply.started":"2022-06-16T16:11:58.552707Z","shell.execute_reply":"2022-06-16T16:11:58.569509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nsns.set()\nfrom IPython.core.pylabtools import figsize\nfigsize(20, 20)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.572142Z","iopub.execute_input":"2022-06-16T16:11:58.572505Z","iopub.status.idle":"2022-06-16T16:11:58.588585Z","shell.execute_reply.started":"2022-06-16T16:11:58.572472Z","shell.execute_reply":"2022-06-16T16:11:58.587324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Just disable some annoying warning\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.591108Z","iopub.execute_input":"2022-06-16T16:11:58.591491Z","iopub.status.idle":"2022-06-16T16:11:58.601672Z","shell.execute_reply.started":"2022-06-16T16:11:58.591458Z","shell.execute_reply":"2022-06-16T16:11:58.600777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read and parse dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/islamic-news/Data artikel islam true xls.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.602608Z","iopub.execute_input":"2022-06-16T16:11:58.602942Z","iopub.status.idle":"2022-06-16T16:11:58.645196Z","shell.execute_reply.started":"2022-06-16T16:11:58.602911Z","shell.execute_reply":"2022-06-16T16:11:58.644145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset investigation","metadata":{}},{"cell_type":"markdown","source":"## Samples Count","metadata":{}},{"cell_type":"code","source":"df.count()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.646708Z","iopub.execute_input":"2022-06-16T16:11:58.647183Z","iopub.status.idle":"2022-06-16T16:11:58.658169Z","shell.execute_reply.started":"2022-06-16T16:11:58.647153Z","shell.execute_reply":"2022-06-16T16:11:58.657134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.kategori.value_counts().plot.barh()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.659594Z","iopub.execute_input":"2022-06-16T16:11:58.662355Z","iopub.status.idle":"2022-06-16T16:11:58.966525Z","shell.execute_reply.started":"2022-06-16T16:11:58.662311Z","shell.execute_reply":"2022-06-16T16:11:58.965321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset preprocessing and feature extraction","metadata":{}},{"cell_type":"markdown","source":"## Text preprocessing \n\nIn order to extract features from raw text, we have to somehow preprocess it. Typical simplified text preprocessing workflow:\n\n<img src=\"https://i.ibb.co/Prrpgxg/nlp-preproc.png\" />\n\n1. **Tokenization** - inteligent splitting text into some kind of tokens (sentences, words, etc.)\n2. **Cleaning** - cleaning text from all undesirable symbols or tokens or lines or whatever, it could be for example stop words or punctuation. \n3. **Steaming** - rocess of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. [refference](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python)\n4. **Lemmatization** - unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words. [refference](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python)\n5. **Feature extraction** - vectorization of the ouput stems/lemmas. For example counting for each document or using TF-IDF.\n\nIn our case I have chosen such workflow:\n1. **Tokenization** - using [spaCy](https://spacy.io/) python library\n2. **Cleaning** - after investigating the content of raw emails, I have decided the next steps:\n    1. Delete symbols ```!\"#%&\\'*+,-<=>?[\\\\]^_`{|}~```\n    2. Delete lines, which begins with `From:` or end with `writes:`, autogenerated content by email host.\n    3. Delete `email strings`, `From:`, `Re:`, `Subject:`\n    4. Delete numbers\n3. **Lemmatization** - I have chosen lemmatization(`spaCy`) in favor of steaming(`nltk`), because it has shown ability to generate more robust results. I've used [spaCy](https://spacy.io/) python library. \n4. **Feature extraction** - TF-IDF","metadata":{}},{"cell_type":"code","source":"import re\nimport string\n\nfrom sklearn.base import TransformerMixin\n\nclass TextPreprocessor(TransformerMixin):\n    def __init__(self, text_attribute):\n        self.text_attribute = text_attribute\n        \n    def transform(self, X, *_):\n        X_copy = X.copy()\n        X_copy[self.text_attribute] = X_copy[self.text_attribute].apply(self._preprocess_text)\n        return X_copy\n    \n    def _preprocess_text(self, text):\n        return self._lemmatize(self._leave_letters_only(self._clean(text)))\n    \n    def _clean(self, text):\n        bad_symbols = '!\"#%&\\'*+,-<=>?[\\\\]^_`{|}~'\n        text_without_symbols = text.translate(str.maketrans('', '', bad_symbols))\n\n        text_without_bad_words = ''\n        for line in text_without_symbols.split('\\n'):\n            if not line.lower().startswith('from:') and not line.lower().endswith('writes:'):\n                text_without_bad_words += line + '\\n'\n\n        clean_text = text_without_bad_words\n        email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n        regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n        for r in regexes_to_remove:\n            clean_text = re.sub(r, '', clean_text)\n\n        return clean_text\n    \n    def _leave_letters_only(self, text):\n        text_without_punctuation = text.translate(str.maketrans('', '', string.punctuation))\n        return ' '.join(re.findall(\"[a-zA-Z]+\", text_without_punctuation))\n    \n    def _lemmatize(self, text):\n        doc = nlp(text)\n        words = [x.lemma_ for x in [y for y in doc if not y.is_stop and y.pos_ != 'PUNCT' \n                                    and y.pos_ != 'PART' and y.pos_ != 'X']]\n        return ' '.join(words)\n    \n    def fit(self, *_):\n        return self","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.967882Z","iopub.execute_input":"2022-06-16T16:11:58.968249Z","iopub.status.idle":"2022-06-16T16:11:58.983276Z","shell.execute_reply.started":"2022-06-16T16:11:58.968216Z","shell.execute_reply":"2022-06-16T16:11:58.982335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_preprocessor = TextPreprocessor(text_attribute='artikel')\ndf_preprocessed = text_preprocessor.transform(df)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:11:58.984664Z","iopub.execute_input":"2022-06-16T16:11:58.985301Z","iopub.status.idle":"2022-06-16T16:12:06.350491Z","shell.execute_reply.started":"2022-06-16T16:11:58.985267Z","shell.execute_reply":"2022-06-16T16:12:06.34962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature extraction\n\nTo train TF-IDF vectorizer we have to split our dataset into `train`/`test` parts, I have chosen typical `70`/`30` ratio.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain, test = train_test_split(df_preprocessed, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:12:06.351549Z","iopub.execute_input":"2022-06-16T16:12:06.35239Z","iopub.status.idle":"2022-06-16T16:12:06.357507Z","shell.execute_reply.started":"2022-06-16T16:12:06.352359Z","shell.execute_reply":"2022-06-16T16:12:06.356834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To make **TF-IDF** vectorizer efficient, we have to specify rather large vocabulary(`max_features`). It causes very very large dataset dimensionality. Usually this causes RAM issues or computational time issues on the model training step. Therefore, `sklearn.feature_extraction.text.TfidfVectorizer` returns sparse matrix as the output, which is much more memmory efficient and computational time efficient for some classifier models, which are able to deal with sparse matrices. But some of further preprocessing steps, are not able to deal with this, so the next steps will be very memory-consuming. Because of that I have chosen only `10 000` words vocabulary.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer()\n\nX_tfidf_train = tfidf_vectorizer.fit_transform(train['artikel'])\nX_tfidf_test = tfidf_vectorizer.transform(test['artikel'])\n\nprint(X_tfidf_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:36:53.889585Z","iopub.execute_input":"2022-06-16T16:36:53.89023Z","iopub.status.idle":"2022-06-16T16:36:53.956556Z","shell.execute_reply.started":"2022-06-16T16:36:53.890189Z","shell.execute_reply":"2022-06-16T16:36:53.955531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = train['kategori']\ny_test = test['kategori']\n\nprint({}, y.shape)\nprint({}, y_test.shape)\n\nX = X_tfidf_train\nx_test = X_tfidf_test","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:38:07.194516Z","iopub.execute_input":"2022-06-16T16:38:07.194944Z","iopub.status.idle":"2022-06-16T16:38:07.202365Z","shell.execute_reply.started":"2022-06-16T16:38:07.194913Z","shell.execute_reply":"2022-06-16T16:38:07.201005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training and evaluation\n\nI've tried more than 10 different model instances, with a great batch of different hyperparameters. The experimets were held using `sklearn.model_selection.GridSearchCV` with cross validation size 5. These experiments run more than 2 days non stop on my PC, and here I want to show condensed results of 5 models, their evaluation and result selection","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.naive_bayes import MultinomialNB, ComplementNB\nfrom sklearn.svm import LinearSVC\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:38:44.738025Z","iopub.execute_input":"2022-06-16T16:38:44.738483Z","iopub.status.idle":"2022-06-16T16:38:44.744629Z","shell.execute_reply.started":"2022-06-16T16:38:44.73844Z","shell.execute_reply":"2022-06-16T16:38:44.743895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this snippet was taken from https://gist.github.com/shaypal5/94c53d765083101efc0240d776a23823\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.utils.multiclass import unique_labels\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef print_confusion_matrix(confusion_matrix, \n                           class_names, \n                           figsize = (15,15), \n                           fontsize=12,\n                           ylabel='True label',\n                           xlabel='Predicted label'):\n    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n    \n    Arguments\n    ---------\n    confusion_matrix: numpy.ndarray\n        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n        Similarly constructed ndarrays can also be used.\n    class_names: list\n        An ordered list of class names, in the order they index the given confusion matrix.\n    figsize: tuple\n        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n        the second determining the vertical size. Defaults to (10,7).\n    fontsize: int\n        Font size for axes labels. Defaults to 14.\n        \n    Returns\n    -------\n    matplotlib.figure.Figure\n        The resulting confusion matrix figure\n    \"\"\"\n    df_cm = pd.DataFrame(\n        confusion_matrix, index=class_names, columns=class_names, \n    )\n    fig = plt.figure(figsize=figsize)\n    try:\n        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n    except ValueError:\n        raise ValueError(\"Confusion matrix values must be integers.\")\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n    plt.ylabel(ylabel)\n    plt.xlabel(xlabel)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:38:53.397286Z","iopub.execute_input":"2022-06-16T16:38:53.397819Z","iopub.status.idle":"2022-06-16T16:38:53.412486Z","shell.execute_reply.started":"2022-06-16T16:38:53.39778Z","shell.execute_reply":"2022-06-16T16:38:53.411256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, X, y, X_test, y_test, target_names=None):\n    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n    scores_test = cross_val_score(model, X_test, y_test, cv=5, scoring='accuracy')\n    \n    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n    print(\"Accuracy test: %0.2f (+/- %0.2f)\" % (scores_test.mean(), scores_test.std()))\n    \n    print(\"Test classification report: \")\n    if target_names is None:\n        target_names = model.classes_\n    print(classification_report(y_test, model.predict(X_test), target_names=target_names))\n    print(\"Test confusion matrix: \")\n    print_confusion_matrix(confusion_matrix(y_test, model.predict(X_test)), class_names=target_names)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:39:01.991617Z","iopub.execute_input":"2022-06-16T16:39:01.992314Z","iopub.status.idle":"2022-06-16T16:39:02.002145Z","shell.execute_reply.started":"2022-06-16T16:39:01.992262Z","shell.execute_reply":"2022-06-16T16:39:02.000958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multinominal Naive Bayes\n\nFor `MultinomialNB` we see that the most misclassified groups are `alt.atheism`, `talk.politics.misc` and `talk.religion.misc`. A lot of `talk.religion.misc` were classified into very close group `soc.religion.christian`. And probably in this dataset contains mostly republican mails, if so many `talk.politics.misc` were classified in `talk.politics.guns`.","metadata":{}},{"cell_type":"code","source":"mb = MultinomialNB()\nmb.fit(X_selected, y_resampled)\nevaluate_model(mb, X_selected, y, X_test_selected, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:40:20.985968Z","iopub.execute_input":"2022-06-16T16:40:20.987084Z","iopub.status.idle":"2022-06-16T16:40:21.544905Z","shell.execute_reply.started":"2022-06-16T16:40:20.987012Z","shell.execute_reply":"2022-06-16T16:40:21.543758Z"},"trusted":true},"execution_count":null,"outputs":[]}]}